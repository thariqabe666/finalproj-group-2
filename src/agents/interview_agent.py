import os
import speech_recognition as sr
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class InterviewAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
        
        # Prompt yang mewajibkan AI menjawab sesuai bahasa user
        self.prompt = ChatPromptTemplate.from_template("""
            You are a professional Interviewer. 
            
            JOB DESCRIPTION:
            {job_description}
            
            CANDIDATE CV:
            {cv_text}
            
            HISTORY: {history}
            CANDIDATE ANSWER: {answer}
            
            INSTRUCTIONS:
            1. Response in the SAME LANGUAGE as the candidate.
            2. Give brief feedback on the answer based on the job requirements and candidate's CV.
            3. Ask exactly ONE follow-up question that is relevant to the role and the candidate's previous answer.
            
            YOUR RESPONSE:
        """)

    def get_response(self, history, user_answer, job_description, cv_text):
        chain = self.prompt | self.llm | StrOutputParser()
        return chain.invoke({
            "history": history, 
            "answer": user_answer,
            "job_description": job_description,
            "cv_text": cv_text
        })

    def listen(self):
        """
        Listens to the microphone and converts speech to text using OpenAI Whisper (via SpeechRecognition if available or API).
        For this implementation, we'll use local Google Speech Recognition as a default fallback, 
        or specifically configured for Whisper API if the user has keys/setup.
        
        To keep it simple and robust:
        We will use `recognizer.recognize_google` for quick testing if Whisper API isn't explicitly requested 
        but the plan mentioned "Send audio to OpenAI Whisper". 
        
        To use OpenAI Whisper API via speech_recognition:
        recognizer.recognize_whisper_api(audio, api_key=OPENAI_API_KEY)
        """
        with sr.Microphone() as source:
            print("\nListening... (Speak now)")
            # Adjust for ambient noise
            self.recognizer.adjust_for_ambient_noise(source, duration=1)
            try:
                audio = self.recognizer.listen(source, timeout=10, phrase_time_limit=30)
                print("Processing audio...")
                
                # Using OpenAI Whisper API for better accuracy
                api_key = os.getenv("OPENAI_API_KEY")
                if api_key:
                    text = self.recognizer.recognize_whisper_api(audio, api_key=api_key)
                else:
                    # Fallback to Google if no key (though this project seems to have one)
                    text = self.recognizer.recognize_google(audio)
                
                print(f"You said: {text}")
                return text
            except sr.WaitTimeoutError:
                print("No speech detected.")
                return None
            except sr.UnknownValueError:
                print("Could not understand audio.")
                return None
            except sr.RequestError as e:
                print(f"Could not request results; {e}")
                return None

    def run(self):
        """
        Starts the interview loop.
        """
        print("Starting Mock Interview Agent...")
        print("Say 'exit' or 'stop' to end the interview.")
        
        # Initial greeting
        initial_question = "Tell me about yourself and your background in software engineering."
        print(f"\nAgent: {initial_question}")
        self.history += f"Agent: {initial_question}\n"
        
        while True:
            # 1. Listen
            user_input = self.listen()
            
            if not user_input:
                continue
                
            if user_input.lower() in ["exit", "stop", "quit", "bye"]:
                print("Ending interview. Good luck!")
                break
            
            # 2. Update History
            self.history += f"Candidate: {user_input}\n"
            
            # 3. Generate Response
            chain = self.prompt | self.llm | StrOutputParser()
            response = chain.invoke({"history": self.history, "answer": user_input})
            
            # 4. Output Response
            print(f"\nAgent: {response}")
            
            # 5. Update History with Agent response
            self.history += f"Agent: {response}\n"
            

if __name__ == "__main__":
    agent = InterviewAgent()
    agent.run()
